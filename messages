2. In your Python code, you will need to initialize the Datadog API with your API and APP keys.
from datadog import initialize, api

# Datadog API/APP key configuration
options = {
    'api_key': 'YOUR_API_KEY',
    'app_key': 'YOUR_APP_KEY'
}

initialize(**options)
get the api_key and app_key from your Datadog account by navigating to API Settings under Integration.

3.integrate Datadog with Pythonâ€™s built-in logging module. The DatadogHandler can be set up to send logs to Datadog.
import logging
from datadog import initialize, statsd
from datadog.api.exceptions import ApiError
from datadog import ThreadStats

# Setup API and APP keys for initialization
options = {
    'api_key': 'YOUR_API_KEY',
    'app_key': 'YOUR_APP_KEY'
}

initialize(**options)

# Initialize Datadog logging
logger = logging.getLogger('datadog_logger')
logger.setLevel(logging.INFO)

# Datadog handler to send logs to Datadog
try:
    from datadog import DDHandler
    handler = DDHandler('YOUR_API_KEY')
    logger.addHandler(handler)

except ApiError as e:
    print(f"Failed to send log to Datadog: {e}")

# Log example
logger.info("This is a test log sent to Datadog")

4.docker thing
# Combine user/group creation
RUN groupadd -g 603 appgrp && \
    useradd --disabled-password -u 500 -g 603 appusr




u6u7pRsRGMFP2Kh

RUN groupadd -g 603 appgrp && \
    useradd --disabled-password -u 500 -g 603 appusr



'ssl.endpoint.identification.algorithm': 'none',  # Disable hostname verification
    'enable.ssl.certificate.verification': 'false'






return {
            "deserialized_message": deserialized_value,
            "partition": msg.partition(),
            "offset": msg.offset(),
            "key": msg.key()
        }



if result:
    print(f"Deserialized message: {result['deserialized_message']}")
    print(f"Partition: {result['partition']}")
    print(f"Offset: {result['offset']}")
    print(f"Key: {result['key']}")
else:
    print("Error occurred during message consumption.")


how to call

from kafka_consumer import GenericKafkaConsumer
# Create an instance of the GenericKafkaConsumer class
kafka_consumer = GenericKafkaConsumer(
    bootstrap_server="b-3.mskrwfdde001.jqjxhu.c23.kafka.us-east-1.amazonaws.com:9092",
    consumer_group_id="fr-rwds-eds-consumer-group",
    topic_name="fr-rwcs-rsp-group",
    schema_registry_url="https://schema-registry-dev.fitchritings.com"
)

# Call the consume_messages() method
result = kafka_consumer.consume_messages()
if result:
    print(f"Deserialized message: {result['deserialized_message']}")
    print(f"Partition: {result['partition']}")
    print(f"Offset: {result['offset']}")
    print(f"Key: {result['key']}")
else:
    print("Error occurred during message consumption.")
